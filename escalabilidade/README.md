# ğŸš€ Escalabilidade de Sistemas DistribuÃ­dos  

## ğŸ— 3 Pilares da Escalabilidade  
### ğŸ—‚ Caching  
âœ” Reduz a sobrecarga em serviÃ§os crÃ­ticos.  
âœ” Melhora o tempo de resposta armazenando dados frequentemente acessados.  
âœ” Diminui a latÃªncia posicionando os dados prÃ³ximos ao usuÃ¡rio.  

### ğŸ”„ Processamento AssÃ­ncrono  
âœ” Posterga tarefas nÃ£o essenciais para execuÃ§Ã£o posterior.  
âœ” Libera recursos para operaÃ§Ãµes imediatas, melhorando a capacidade do sistema.  

### âš– Balanceamento de Carga  
âœ” Distribui requisiÃ§Ãµes entre mÃºltiplas instÃ¢ncias, evitando gargalos.  
âœ” Divide tarefas pesadas para otimizar recursos.  

âš  **Sem boas prÃ¡ticas, os pilares nÃ£o garantem escalabilidade!**  

---

## ğŸ“Œ Construindo um Sistema EscalÃ¡vel  
ğŸ”¹ A escalabilidade depende do contexto, requisitos e restriÃ§Ãµes do sistema.  

### ğŸ”¥ Desafios CrÃ­ticos  
âœ… **LatÃªncia**: Minimizar tempo de resposta de operaÃ§Ãµes crÃ­ticas.  
âœ… **Throughput**: Aumentar requisiÃ§Ãµes processadas por segundo.  
âœ… **SincronizaÃ§Ã£o Excessiva**: Reduzir dependÃªncia de processos sÃ­ncronos para evitar bloqueios.  

---

## âŒ As 8 FalÃ¡cias de Sistemas DistribuÃ­dos  
1. A rede Ã© sempre confiÃ¡vel.  
2. A latÃªncia Ã© zero.  
3. A largura de banda Ã© infinita.  
4. A rede Ã© segura.  
5. A topologia da rede nunca muda.  
6. Existe apenas um administrador.  
7. O transporte de dados Ã© sempre confiÃ¡vel.  
8. A rede Ã© homogÃªnea.  

---

## âš  Modos de Falha em Sistemas DistribuÃ­dos  
Mesmo em sistemas simples, falhas sÃ£o inevitÃ¡veis.  

ğŸ”¹ **Chamadas Locais (Local Calls)**: ComunicaÃ§Ã£o dentro da mesma aplicaÃ§Ã£o.  
ğŸ”¹ **Chamadas Remotas (Remote Calls)**: ComunicaÃ§Ã£o via rede, sujeita a:  
âœ” Perda de pacotes  
âœ” LatÃªncia variÃ¡vel  
âœ” Problemas de roteamento  

ğŸ“Œ **Falhas Sempre Ocorrem**:  
ğŸ’€ Hardware falha (discos quebram, servidores caem).  
ğŸ Software falha (bugs, deadlocks, vazamento de memÃ³ria).  

ğŸ”¹ **Bons arquitetos escolhem tecnologias conhecendo suas desvantagens.**  

---

## ğŸ— MicrosserviÃ§os: Mais que uma SoluÃ§Ã£o TÃ©cnica  
âœ” **Escalabilidade de times**  
âœ” **Entrega contÃ­nua e independÃªncia de deploy**  
âœ” **Melhor modularidade e manutenÃ§Ã£o**  

---

# ğŸŒ Arquitetura Web, Performance e Escalabilidade  

## ğŸš€ Fundamentos da Arquitetura Web  
1ï¸âƒ£ Um servidor executa a aplicaÃ§Ã£o.  
2ï¸âƒ£ Um navegador faz requisiÃ§Ãµes para o servidor web.  
3ï¸âƒ£ O servidor processa a requisiÃ§Ã£o, acessa o banco de dados e responde ao navegador.  

---

## ğŸ“Œ Conceitos Essenciais  
| Conceito         | DefiniÃ§Ã£o |
|-----------------|-----------|
| **Performance** | Tempo de resposta (**latÃªncia**) |
| **Escalabilidade** | Quantidade de requisiÃ§Ãµes processadas por segundo (**throughput**) |

âœ” **Meta:** Aumentar throughput mantendo baixa latÃªncia.  

---

## ğŸ” Como Melhorar o Throughput?  

### ğŸ“Š **Benchmarking e Teste de Carga**  
ğŸ”¹ Descobrir limites do sistema.  
ğŸ”¹ Identificar o **ponto de saturaÃ§Ã£o** (onde throughput cai e latÃªncia aumenta).  

### âš  Otimizar para LatÃªncia vs. Throughput  

| Otimizar para LatÃªncia | Otimizar para Throughput |
|------------------------|-------------------------|
| Usar **menos recursos** | **Aumentar recursos** |
| Responder **mais rÃ¡pido** | Processar **mais requisiÃ§Ãµes** |
| **Liberar CPU** rapidamente | **Manter CPU ocupada** |

âœ” **Sistemas distribuÃ­dos geralmente sÃ£o limitados pela CPU**.  
âœ” **Garbage Collector concorre com processamento da aplicaÃ§Ã£o**.  
âœ” **Otimizar para throughput** = Extrair mÃ¡ximo do poder computacional.  
âœ” **Otimizar para latÃªncia** = Melhor gerenciar os recursos do servidor.  

---

## ğŸ›  Como Descobrir os Limites do Sistema?  

### ğŸ”¥ Ferramentas de Teste de Carga e Estresse  
âœ” **Apache JMeter**  
âœ” **Gatling**  
âœ” **k6**  
âœ” **Grafana**  
âœ” **Prometheus**  


# ğŸ“Š Entendendo a DistribuiÃ§Ã£o do Workload  

## ğŸš€ O Que Analisar?  
ğŸ”¹ O workload Ã© mais de **leitura** ou **escrita**?  
ğŸ”¹ O gargalo estÃ¡ na **CPU** ou no **I/O** (banco de dados, disco, rede)?  
ğŸ”¹ O trÃ¡fego ocorre mais de **dia** ou **noite**?  
ğŸ”¹ As requisiÃ§Ãµes sÃ£o **em tempo real** ou **processadas em lote**?  

---

## ğŸ“Œ **NÃ£o Confie Apenas na MÃ©dia!**  
âœ” A mÃ©dia pode esconder padrÃµes crÃ­ticos de carga.  
âœ” O uso de **histogramas** ajuda a visualizar a distribuiÃ§Ã£o real do throughput ao longo do dia.  

---

# ğŸ”¥ Medindo a Qualidade das RequisiÃ§Ãµes  

## âš¡ **LatÃªncia NÃ£o Ã‰ Fixa!**  
A latÃªncia pode variar por vÃ¡rios motivos:  
âœ” **Garbage Collector**  
âœ” **Problemas de indexaÃ§Ã£o no banco**  
âœ” **InterrupÃ§Ãµes no sistema**  
âœ” **Limpeza de cache**  
âœ” **Congestionamento de rede**  

---

## ğŸ¯ Percentis > MÃ©dia  
ğŸ”¹ **Percentis sÃ£o mais Ãºteis do que a mÃ©dia** para detectar gargalos.  
ğŸ”¹ Um **histograma de latÃªncia** permite visualizar o comportamento real do sistema.  
ğŸ”¹ Se o foco for otimizaÃ§Ã£o, os percentis indicam **onde atacar os gargalos**.  

---

## âš  **Taxa de Erro (Error Rate)**  
ğŸ”¹ **Apenas throughput e latÃªncia nÃ£o bastam!**  
ğŸ”¹ Um **alto throughput** pode estar mascarando falhas na aplicaÃ§Ã£o.  
ğŸ”¹ **Monitorar taxa de erro** evita interpretaÃ§Ãµes erradas sobre a qualidade do sistema.  

# ğŸš€ De MÃ¡quina Local para um Sistema DistribuÃ­do  

## ğŸ”¥ 5 Passos Essenciais  

### 1ï¸âƒ£ **Otimizar a AplicaÃ§Ã£o**  
âœ” **Ajustar a JVM**:  
- Configurar **tamanho ideal de memÃ³ria** (RAM).  
- Definir **mÃ­nimo e mÃ¡ximo de memÃ³ria iguais** para evitar realocaÃ§Ã£o dinÃ¢mica.  
- Escolher um **Garbage Collector eficiente** para a aplicaÃ§Ã£o.  
- Para **Java 17+ em containers**, configurar `MaxRAMPercentage=75%` para evitar desperdÃ­cio de memÃ³ria.  

---

### 2ï¸âƒ£ **Melhorar a MÃ¡quina**  
âœ” **Scale Up** (aumentar recursos de uma mÃ¡quina).  
âš  **LimitaÃ§Ã£o**: Crescimento nÃ£o linear entre custo e performance.  

---

### 3ï¸âƒ£ **Adicionar Mais MÃ¡quinas (Scale Out)**  
âœ” **Balanceador de carga (NGINX, HAProxy, etc.)**  
âœ” **Escala horizontalmente** (mais barato que Scale Up).  
âš  **Problema: Sticky Session**  
- O balanceador mantÃ©m afinidade entre usuÃ¡rio e uma mÃ¡quina especÃ­fica.  
- Se essa mÃ¡quina falhar, o usuÃ¡rio perde sua sessÃ£o.  

---

### 4ï¸âƒ£ **Replicar Estado**  
âœ” **Session Replication**:  
- As sessÃµes sÃ£o replicadas entre as mÃ¡quinas do cluster.  
âœ” **Alta disponibilidade** â†’ Scale Out + Session Replication.  
âš  **Custo alto**:  
- **Mais consumo de rede, memÃ³ria e CPU** conforme o cluster cresce.  

---

### 5ï¸âƒ£ **Remover Estado (Stateless Architecture)**  
âœ” **Armazenar estado fora das mÃ¡quinas do cluster** â†’ **Cache distribuÃ­do (Redis, Memcached)**.  
âœ” **Cada requisiÃ§Ã£o pode ser atendida por qualquer mÃ¡quina**.  
âœ” **Melhor escalabilidade** e **menos dependÃªncia de replicaÃ§Ã£o de sessÃ£o**.  
âœ” Pode ser necessÃ¡rio um **cluster de Redis** para evitar pontos Ãºnicos de falha.  

# ğŸš€ Como Rastrear e Tratar Falhas em Sistemas EscalÃ¡veis

## ğŸ”¥ Os 20% que Explicam 80% das Falhas

### 1ï¸âƒ£ Logs Estruturados e Centralizados
- âœ” Use **JSON** para facilitar anÃ¡lise e busca.
- âœ” Envie logs para uma ferramenta centralizada (**ELK Stack, Grafana Loki, Datadog**).
- âœ” Registre logs com **correlaÃ§Ã£o de IDs** para rastrear requisiÃ§Ãµes distribuÃ­das.

---

### 2ï¸âƒ£ Monitoramento ContÃ­nuo
- âœ” Utilize mÃ©tricas (**Prometheus, Grafana, New Relic, Datadog**).
- âœ” Acompanhe **CPU, memÃ³ria, latÃªncia, throughput e taxa de erro**.
- âœ” Configure **alertas** para anomalias.

---

### 3ï¸âƒ£ Tracing DistribuÃ­do (Observabilidade)
- âœ” Ferramentas como **Jaeger, Zipkin, OpenTelemetry** ajudam a entender fluxos de requisiÃ§Ã£o.
- âœ” **Adicione IDs Ãºnicos em cada requisiÃ§Ã£o** para rastrear onde ocorrem gargalos.

---

### 4ï¸âƒ£ Retries e Circuit Breakers
- âœ” Use **retries** com **exponential backoff** para falhas temporÃ¡rias.
- âœ” **Circuit Breaker** (**Resilience4j, Hystrix**) impede sobrecarga em serviÃ§os instÃ¡veis.

---

### 5ï¸âƒ£ Fallbacks e Graceful Degradation
- âœ” Se um serviÃ§o falhar, forneÃ§a **dados cacheados** ou uma **resposta alternativa**.
- âœ” Em **falhas parciais**, degrade funcionalidades sem impactar toda a aplicaÃ§Ã£o.

---

### 6ï¸âƒ£ Testes de ResiliÃªncia
- âœ” Simule falhas com **Chaos Engineering** (**Chaos Monkey, Gremlin**).
- âœ” Realize **Testes de Carga** para encontrar pontos de saturaÃ§Ã£o antes que ocorra um problema real.

---

ğŸ“Œ **Sistemas escalÃ¡veis nÃ£o evitam falhas, mas as tratam da forma menos impactante possÃ­vel!**

# DefiniÃ§Ã£o de Workload de uma AplicaÃ§Ã£o

Existem vÃ¡rias formas de definir o **workload** de uma aplicaÃ§Ã£o. Duas principais categorias sÃ£o:

## I/O Bound vs CPU Bound

### âš¡ I/O Bound
- **DefiniÃ§Ã£o:** Grande parte do tempo de execuÃ§Ã£o Ã© gasto esperando por operaÃ§Ãµes de **I/O** (como comunicaÃ§Ã£o em rede, acesso ao banco de dados, leitura de disco, interaÃ§Ã£o com sistemas externos, etc).
- **CaracterÃ­sticas:** 
  - Sistemas distribuÃ­dos geralmente se encaixam aqui.
  - A performance Ã© frequentemente limitada pela **I/O**.
  - A tunagem de **I/O** pode melhorar significativamente a performance.

### ğŸ’» CPU Bound
- **DefiniÃ§Ã£o:** A maior parte do tempo de execuÃ§Ã£o Ã© usada pela **CPU**, com pouco tempo gasto em I/O.
- **CaracterÃ­sticas:**
  - A performance da aplicaÃ§Ã£o Ã© limitada pela capacidade de processamento da **CPU**.

---

# Gargalos de Performance na Camada de PersistÃªncia

A maioria dos gargalos de performance estÃ£o relacionados Ã  camada de persistÃªncia. Por isso, investir tempo na otimizaÃ§Ã£o dessa camada Ã© crucial.

## TransaÃ§Ã£o com o Banco de Dados

### â³ 1. Tempo para Adquirir ConexÃ£o
- **Importante:** NÃ£o podemos permitir que a aplicaÃ§Ã£o abra conexÃµes de forma descontrolada.
- **SoluÃ§Ã£o:** Configurar o pool de conexÃµes (mÃ­nimo e mÃ¡ximo) para otimizar o uso de conexÃµes.
  - **BenefÃ­cio:** Evita abertura e fechamento desnecessÃ¡rio de conexÃµes, o que acelera a comunicaÃ§Ã£o.
  - **Dica:** Quando o banco responde mais rÃ¡pido, o throughput aumenta. Portanto, um pool de conexÃµes menor Ã© muitas vezes mais eficiente.
  - **ObservaÃ§Ã£o:** NÃ£o hÃ¡ mÃ¡gica aqui; Ã© necessÃ¡rio mensurar e testar para definir o tamanho adequado do pool.

### ğŸ”„ 2. Tempo de RequisiÃ§Ã£o com o Banco
- **SoluÃ§Ã£o:** Habilitar **batch size** e realizar operaÃ§Ãµes em lote.
  - **BenefÃ­cio:** Menos round trips e menor tempo de resposta.

### ğŸ› ï¸ 3. Tempo de ExecuÃ§Ã£o no Banco
- **OtimizaÃ§Ãµes recomendadas:**
  - Otimizar **queries**.
  - Utilizar ferramentas como **EXPLAIN ANALYZE** e **buffer** para analisar a performance de consultas.
  - **Buscas indexadas** sÃ£o essenciais para melhorar o tempo de execuÃ§Ã£o.
  - **Dica:** Utilize o Ã­ndice para acelerar as buscas.
  - **Use funÃ§Ãµes de janela** (**window functions**) para otimizar o processamento de dados no banco.
  - **Levar o processamento para perto dos dados** (como procedures) pode reduzir a latÃªncia, embora haja controvÃ©rsias sobre a centralizaÃ§Ã£o das regras de negÃ³cio.

### â±ï¸ 4. Tempo de Resposta do Banco
- **SoluÃ§Ãµes recomendadas:**
  - Use **consultas planejadas** (projection) para limitar os dados retornados.
  - **Evite o problema de N+1 queries** (select N+1).
  - Configure o relacionamento **um para muitos** como **eager loading** (se a entidade filha for necessÃ¡ria e nÃ£o impactar outros casos de uso).
  - Implemente **paginaÃ§Ã£o** nas consultas para diminuir a quantidade de dados recuperados.

  **BenefÃ­cio:** Menos dados retornados resultam em um tempo de resposta mais rÃ¡pido.

### ğŸ’¤ 5. Tempo que a TransaÃ§Ã£o Fica Ociosa
- **Dica:** O **transaction response time** (considerando as otimizaÃ§Ãµes acima) deve ser o menor possÃ­vel para aumentar o throughput.
- **Nota importante:** Criar novas conexÃµes com o banco de dados Ã© uma operaÃ§Ã£o cara. Portanto, o pool de conexÃµes deve ser otimizado para evitar criaÃ§Ã£o excessiva de conexÃµes.

---

# Resumo de Melhores PrÃ¡ticas para OtimizaÃ§Ã£o

- ğŸ“Š **Mensure e teste** as configuraÃ§Ãµes de pool de conexÃµes.
- ğŸ› ï¸ **Prefira operaÃ§Ãµes em lote** para reduzir o nÃºmero de round trips.
- ğŸ” **Otimize as queries** com ferramentas como **EXPLAIN ANALYZE** e **Ã­ndices**.
- ğŸ”„ **Utilize window functions** e mantenha o processamento prÃ³ximo aos dados.
- ğŸ“ **Use consultas planejadas**, **eager loading** e **paginaÃ§Ã£o** para otimizar o tempo de resposta do banco.
- âš¡ **Reduza o transaction response time** para aumentar o throughput e minimizar a ociosidade das transaÃ§Ãµes.


# Cache no Hibernate e Spring Boot

## ğŸ“Œ First Level Cache (Cache de Primeiro NÃ­vel)
- Gerenciado pelo **EntityManager**.
- Armazena entidades dentro do **contexto da transaÃ§Ã£o**.
- Se a mesma busca for feita vÃ¡rias vezes dentro da mesma transaÃ§Ã£o, os dados sÃ£o buscados do cache ao invÃ©s do banco.

## ğŸ“Œ Second Level Cache (Cache de Segundo NÃ­vel)
- Gerenciado pelo **EntityManagerFactory**.
- Cache compartilhado entre diferentes transaÃ§Ãµes.
- **HabilitaÃ§Ã£o no Spring Boot**:
  1. Configurar o Hibernate no `application.properties`.
  2. Anotar as entidades com `@Cacheable` para habilitar o cache.
  3. Cachear relacionamentos se necessÃ¡rio.

**âš ï¸ Apenas isso nÃ£o basta! Precisamos de um Fine Tuning.**

---

## ğŸ¯ EstratÃ©gias de Cache no Hibernate
O Hibernate permite escolher a estratÃ©gia de cache conforme a necessidade:

| EstratÃ©gia | Uso recomendado |
|------------|----------------|
| `read-only` | Melhor para objetos imutÃ¡veis (mais rÃ¡pido e eficiente). |
| `non-strict-read-write` | Para dados nÃ£o crÃ­ticos, onde a consistÃªncia pode ser menor. |
| `read-write` | MantÃ©m consistÃªncia com locks, mas Ã© mais lento. |

---

## ğŸ”§ ConfiguraÃ§Ã£o do Cache
AlÃ©m de ativar e anotar as entidades, Ã© necessÃ¡rio **configurar corretamente o provedor de cache**:

1. **Definir o provedor de cache**  
   - Exemplo: `EhcacheCachingProvider`.
   
2. **Configurar regiÃµes de memÃ³ria**  
   - Usando `JCacheRegionFactory`.

3. **Especificar o arquivo de configuraÃ§Ã£o do EhCache**  
   - Definir polÃ­ticas de cache no arquivo XML (`ehcache.xml`).

4. **ConfiguraÃ§Ã£o por entidade**  
   - No arquivo `ehcache.xml`, configurar regras individuais para cada entidade cacheada.

---

## ğŸš€ BenefÃ­cios do Cache
Atacamos diretamente o **Response Time**, melhorando:
- **Tempo de RequisiÃ§Ã£o**
- **Tempo de ExecuÃ§Ã£o**
- **Tempo de Resposta**

Isso resulta em uma grande melhoria na **latÃªncia** e no **throughput**.

---

## ğŸ› ï¸ Cache no Spring Boot REST API
TambÃ©m podemos usar cache em APIs REST, por exemplo, em **controllers**, com a anotaÃ§Ã£o:

```java
@Cacheable("usuarios")
public Usuario getUsuario(Long id) {
    return usuarioRepository.findById(id).orElseThrow();
}
```

# ğŸš€ Processamento AssÃ­ncrono e Gerenciamento de Carga

## â³ NÃ£o processe hoje o que vocÃª pode processar amanhÃ£
- Processamentos que envolvem escrita e operaÃ§Ãµes pesadas sÃ£o **custosos**.
- Se um processamento Ã© custoso, ele pode se tornar um **gargalo** no sistema.
- A soluÃ§Ã£o para isso Ã© o **processamento assÃ­ncrono**.

---

## âš™ï¸ Uso do `@Async` no Spring
- O Spring oferece a anotaÃ§Ã£o `@Async`, permitindo a execuÃ§Ã£o assÃ­ncrona de mÃ©todos.
- Para cada requisiÃ§Ã£o anotada com `@Async`, o Spring cria uma nova **thread** para processÃ¡-la.
- Devemos decidir se otimizamos o **pool de threads** para **latÃªncia** ou **throughput**, conforme a necessidade.

 ```java
@Async
public void processarPedido(Long pedidoId) {
    // Processamento assÃ­ncrono aqui
}
```

---

## ğŸ§µ Thread Pool Executor
- O `ThreadPoolExecutor` gerencia chamadas assÃ­ncronas enfileirando processos e alocando-os em **threads especÃ­ficas**.
- Durante **picos de carga**, um pool de threads pode nÃ£o ser suficiente, causando:
  - **Excesso de processos pendentes**
  - **Falta de memÃ³ria (`OutOfMemoryError`)**
  - **ReinicializaÃ§Ã£o da aplicaÃ§Ã£o**
  - **Perda de itens na fila do pool de threads**

---

## ğŸ› ï¸ SoluÃ§Ã£o: Uso de Filas e Brokers
- Para lidar com **picos de carga**, precisamos de **filas mais robustas e durÃ¡veis**.
- Aqui entram os **brokers**, que atuam como **gerenciadores de fila**.

### ğŸ“Œ Substituindo `@Async` por consumidores de fila:
- Em vez de `@Async`, podemos utilizar **consumidores de fila**, como `@JmsListener` ou `@KafkaListener`.
- As **filas absorvem os picos de carga**.
- Os **consumers processam mensagens na taxa que conseguem suportar**.
- Esse mecanismo permite que o prÃ³prio **consumer



