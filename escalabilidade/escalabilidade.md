# üöÄ Escalabilidade de Sistemas Distribu√≠dos  

## üèó 3 Pilares da Escalabilidade  
### üóÇ Caching  
‚úî Reduz a sobrecarga em servi√ßos cr√≠ticos.  
‚úî Melhora o tempo de resposta armazenando dados frequentemente acessados.  
‚úî Diminui a lat√™ncia posicionando os dados pr√≥ximos ao usu√°rio.  

### üîÑ Processamento Ass√≠ncrono  
‚úî Posterga tarefas n√£o essenciais para execu√ß√£o posterior.  
‚úî Libera recursos para opera√ß√µes imediatas, melhorando a capacidade do sistema.  

### ‚öñ Balanceamento de Carga  
‚úî Distribui requisi√ß√µes entre m√∫ltiplas inst√¢ncias, evitando gargalos.  
‚úî Divide tarefas pesadas para otimizar recursos.  

‚ö† **Sem boas pr√°ticas, os pilares n√£o garantem escalabilidade!**  

---

## üìå Construindo um Sistema Escal√°vel  
üîπ A escalabilidade depende do contexto, requisitos e restri√ß√µes do sistema.  

### üî• Desafios Cr√≠ticos  
‚úÖ **Lat√™ncia**: Minimizar tempo de resposta de opera√ß√µes cr√≠ticas.  
‚úÖ **Throughput**: Aumentar requisi√ß√µes processadas por segundo.  
‚úÖ **Sincroniza√ß√£o Excessiva**: Reduzir depend√™ncia de processos s√≠ncronos para evitar bloqueios.  

---

## ‚ùå As 8 Fal√°cias de Sistemas Distribu√≠dos  
1. A rede √© sempre confi√°vel.  
2. A lat√™ncia √© zero.  
3. A largura de banda √© infinita.  
4. A rede √© segura.  
5. A topologia da rede nunca muda.  
6. Existe apenas um administrador.  
7. O transporte de dados √© sempre confi√°vel.  
8. A rede √© homog√™nea.  

---

## ‚ö† Modos de Falha em Sistemas Distribu√≠dos  
Mesmo em sistemas simples, falhas s√£o inevit√°veis.  

üîπ **Chamadas Locais (Local Calls)**: Comunica√ß√£o dentro da mesma aplica√ß√£o.  
üîπ **Chamadas Remotas (Remote Calls)**: Comunica√ß√£o via rede, sujeita a:  
‚úî Perda de pacotes  
‚úî Lat√™ncia vari√°vel  
‚úî Problemas de roteamento  

üìå **Falhas Sempre Ocorrem**:  
üíÄ Hardware falha (discos quebram, servidores caem).  
üêû Software falha (bugs, deadlocks, vazamento de mem√≥ria).  

üîπ **Bons arquitetos escolhem tecnologias conhecendo suas desvantagens.**  

---

## üèó Microsservi√ßos: Mais que uma Solu√ß√£o T√©cnica  
‚úî **Escalabilidade de times**  
‚úî **Entrega cont√≠nua e independ√™ncia de deploy**  
‚úî **Melhor modularidade e manuten√ß√£o**  

---

# üåê Arquitetura Web, Performance e Escalabilidade  

## üöÄ Fundamentos da Arquitetura Web  
1Ô∏è‚É£ Um servidor executa a aplica√ß√£o.  
2Ô∏è‚É£ Um navegador faz requisi√ß√µes para o servidor web.  
3Ô∏è‚É£ O servidor processa a requisi√ß√£o, acessa o banco de dados e responde ao navegador.  

---

## üìå Conceitos Essenciais  
| Conceito         | Defini√ß√£o |
|-----------------|-----------|
| **Performance** | Tempo de resposta (**lat√™ncia**) |
| **Escalabilidade** | Quantidade de requisi√ß√µes processadas por segundo (**throughput**) |

‚úî **Meta:** Aumentar throughput mantendo baixa lat√™ncia.  

---

## üîé Como Melhorar o Throughput?  

### üìä **Benchmarking e Teste de Carga**  
üîπ Descobrir limites do sistema.  
üîπ Identificar o **ponto de satura√ß√£o** (onde throughput cai e lat√™ncia aumenta).  

### ‚ö† Otimizar para Lat√™ncia vs. Throughput  

| Otimizar para Lat√™ncia | Otimizar para Throughput |
|------------------------|-------------------------|
| Usar **menos recursos** | **Aumentar recursos** |
| Responder **mais r√°pido** | Processar **mais requisi√ß√µes** |
| **Liberar CPU** rapidamente | **Manter CPU ocupada** |

‚úî **Sistemas distribu√≠dos geralmente s√£o limitados pela CPU**.  
‚úî **Garbage Collector concorre com processamento da aplica√ß√£o**.  
‚úî **Otimizar para throughput** = Extrair m√°ximo do poder computacional.  
‚úî **Otimizar para lat√™ncia** = Melhor gerenciar os recursos do servidor.  

---

## üõ† Como Descobrir os Limites do Sistema?  

### üî• Ferramentas de Teste de Carga e Estresse  
‚úî **Apache JMeter**  
‚úî **Gatling**  
‚úî **k6**  
‚úî **Grafana**  
‚úî **Prometheus**  


# üìä Entendendo a Distribui√ß√£o do Workload  

## üöÄ O Que Analisar?  
üîπ O workload √© mais de **leitura** ou **escrita**?  
üîπ O gargalo est√° na **CPU** ou no **I/O** (banco de dados, disco, rede)?  
üîπ O tr√°fego ocorre mais de **dia** ou **noite**?  
üîπ As requisi√ß√µes s√£o **em tempo real** ou **processadas em lote**?  

---

## üìå **N√£o Confie Apenas na M√©dia!**  
‚úî A m√©dia pode esconder padr√µes cr√≠ticos de carga.  
‚úî O uso de **histogramas** ajuda a visualizar a distribui√ß√£o real do throughput ao longo do dia.  

---

# üî• Medindo a Qualidade das Requisi√ß√µes  

## ‚ö° **Lat√™ncia N√£o √â Fixa!**  
A lat√™ncia pode variar por v√°rios motivos:  
‚úî **Garbage Collector**  
‚úî **Problemas de indexa√ß√£o no banco**  
‚úî **Interrup√ß√µes no sistema**  
‚úî **Limpeza de cache**  
‚úî **Congestionamento de rede**  

---

## üéØ Percentis > M√©dia  
üîπ **Percentis s√£o mais √∫teis do que a m√©dia** para detectar gargalos.  
üîπ Um **histograma de lat√™ncia** permite visualizar o comportamento real do sistema.  
üîπ Se o foco for otimiza√ß√£o, os percentis indicam **onde atacar os gargalos**.  

---

## ‚ö† **Taxa de Erro (Error Rate)**  
üîπ **Apenas throughput e lat√™ncia n√£o bastam!**  
üîπ Um **alto throughput** pode estar mascarando falhas na aplica√ß√£o.  
üîπ **Monitorar taxa de erro** evita interpreta√ß√µes erradas sobre a qualidade do sistema.  

# üöÄ De M√°quina Local para um Sistema Distribu√≠do  

## üî• 5 Passos Essenciais  

### 1Ô∏è‚É£ **Otimizar a Aplica√ß√£o**  
‚úî **Ajustar a JVM**:  
- Configurar **tamanho ideal de mem√≥ria** (RAM).  
- Definir **m√≠nimo e m√°ximo de mem√≥ria iguais** para evitar realoca√ß√£o din√¢mica.  
- Escolher um **Garbage Collector eficiente** para a aplica√ß√£o.  
- Para **Java 17+ em containers**, configurar `MaxRAMPercentage=75%` para evitar desperd√≠cio de mem√≥ria.  

---

### 2Ô∏è‚É£ **Melhorar a M√°quina**  
‚úî **Scale Up** (aumentar recursos de uma m√°quina).  
‚ö† **Limita√ß√£o**: Crescimento n√£o linear entre custo e performance.  

---

### 3Ô∏è‚É£ **Adicionar Mais M√°quinas (Scale Out)**  
‚úî **Balanceador de carga (NGINX, HAProxy, etc.)**  
‚úî **Escala horizontalmente** (mais barato que Scale Up).  
‚ö† **Problema: Sticky Session**  
- O balanceador mant√©m afinidade entre usu√°rio e uma m√°quina espec√≠fica.  
- Se essa m√°quina falhar, o usu√°rio perde sua sess√£o.  

---

### 4Ô∏è‚É£ **Replicar Estado**  
‚úî **Session Replication**:  
- As sess√µes s√£o replicadas entre as m√°quinas do cluster.  
‚úî **Alta disponibilidade** ‚Üí Scale Out + Session Replication.  
‚ö† **Custo alto**:  
- **Mais consumo de rede, mem√≥ria e CPU** conforme o cluster cresce.  

---

### 5Ô∏è‚É£ **Remover Estado (Stateless Architecture)**  
‚úî **Armazenar estado fora das m√°quinas do cluster** ‚Üí **Cache distribu√≠do (Redis, Memcached)**.  
‚úî **Cada requisi√ß√£o pode ser atendida por qualquer m√°quina**.  
‚úî **Melhor escalabilidade** e **menos depend√™ncia de replica√ß√£o de sess√£o**.  
‚úî Pode ser necess√°rio um **cluster de Redis** para evitar pontos √∫nicos de falha.  

# üöÄ Como Rastrear e Tratar Falhas em Sistemas Escal√°veis

## üî• Os 20% que Explicam 80% das Falhas

### 1Ô∏è‚É£ Logs Estruturados e Centralizados
- ‚úî Use **JSON** para facilitar an√°lise e busca.
- ‚úî Envie logs para uma ferramenta centralizada (**ELK Stack, Grafana Loki, Datadog**).
- ‚úî Registre logs com **correla√ß√£o de IDs** para rastrear requisi√ß√µes distribu√≠das.

---

### 2Ô∏è‚É£ Monitoramento Cont√≠nuo
- ‚úî Utilize m√©tricas (**Prometheus, Grafana, New Relic, Datadog**).
- ‚úî Acompanhe **CPU, mem√≥ria, lat√™ncia, throughput e taxa de erro**.
- ‚úî Configure **alertas** para anomalias.

---

### 3Ô∏è‚É£ Tracing Distribu√≠do (Observabilidade)
- ‚úî Ferramentas como **Jaeger, Zipkin, OpenTelemetry** ajudam a entender fluxos de requisi√ß√£o.
- ‚úî **Adicione IDs √∫nicos em cada requisi√ß√£o** para rastrear onde ocorrem gargalos.

---

### 4Ô∏è‚É£ Retries e Circuit Breakers
- ‚úî Use **retries** com **exponential backoff** para falhas tempor√°rias.
- ‚úî **Circuit Breaker** (**Resilience4j, Hystrix**) impede sobrecarga em servi√ßos inst√°veis.

---

### 5Ô∏è‚É£ Fallbacks e Graceful Degradation
- ‚úî Se um servi√ßo falhar, forne√ßa **dados cacheados** ou uma **resposta alternativa**.
- ‚úî Em **falhas parciais**, degrade funcionalidades sem impactar toda a aplica√ß√£o.

---

### 6Ô∏è‚É£ Testes de Resili√™ncia
- ‚úî Simule falhas com **Chaos Engineering** (**Chaos Monkey, Gremlin**).
- ‚úî Realize **Testes de Carga** para encontrar pontos de satura√ß√£o antes que ocorra um problema real.

---

üìå **Sistemas escal√°veis n√£o evitam falhas, mas as tratam da forma menos impactante poss√≠vel!**

# Defini√ß√£o de Workload de uma Aplica√ß√£o

Existem v√°rias formas de definir o **workload** de uma aplica√ß√£o. Duas principais categorias s√£o:

## I/O Bound vs CPU Bound

### ‚ö° I/O Bound
- **Defini√ß√£o:** Grande parte do tempo de execu√ß√£o √© gasto esperando por opera√ß√µes de **I/O** (como comunica√ß√£o em rede, acesso ao banco de dados, leitura de disco, intera√ß√£o com sistemas externos, etc).
- **Caracter√≠sticas:** 
  - Sistemas distribu√≠dos geralmente se encaixam aqui.
  - A performance √© frequentemente limitada pela **I/O**.
  - A tunagem de **I/O** pode melhorar significativamente a performance.

### üíª CPU Bound
- **Defini√ß√£o:** A maior parte do tempo de execu√ß√£o √© usada pela **CPU**, com pouco tempo gasto em I/O.
- **Caracter√≠sticas:**
  - A performance da aplica√ß√£o √© limitada pela capacidade de processamento da **CPU**.

---

# Gargalos de Performance na Camada de Persist√™ncia

A maioria dos gargalos de performance est√£o relacionados √† camada de persist√™ncia. Por isso, investir tempo na otimiza√ß√£o dessa camada √© crucial.

## Transa√ß√£o com o Banco de Dados

### ‚è≥ 1. Tempo para Adquirir Conex√£o
- **Importante:** N√£o podemos permitir que a aplica√ß√£o abra conex√µes de forma descontrolada.
- **Solu√ß√£o:** Configurar o pool de conex√µes (m√≠nimo e m√°ximo) para otimizar o uso de conex√µes.
  - **Benef√≠cio:** Evita abertura e fechamento desnecess√°rio de conex√µes, o que acelera a comunica√ß√£o.
  - **Dica:** Quando o banco responde mais r√°pido, o throughput aumenta. Portanto, um pool de conex√µes menor √© muitas vezes mais eficiente.
  - **Observa√ß√£o:** N√£o h√° m√°gica aqui; √© necess√°rio mensurar e testar para definir o tamanho adequado do pool.

### üîÑ 2. Tempo de Requisi√ß√£o com o Banco
- **Solu√ß√£o:** Habilitar **batch size** e realizar opera√ß√µes em lote.
  - **Benef√≠cio:** Menos round trips e menor tempo de resposta.

### üõ†Ô∏è 3. Tempo de Execu√ß√£o no Banco
- **Otimiza√ß√µes recomendadas:**
  - Otimizar **queries**.
  - Utilizar ferramentas como **EXPLAIN ANALYZE** e **buffer** para analisar a performance de consultas.
  - **Buscas indexadas** s√£o essenciais para melhorar o tempo de execu√ß√£o.
  - **Dica:** Utilize o √≠ndice para acelerar as buscas.
  - **Use fun√ß√µes de janela** (**window functions**) para otimizar o processamento de dados no banco.
  - **Levar o processamento para perto dos dados** (como procedures) pode reduzir a lat√™ncia, embora haja controv√©rsias sobre a centraliza√ß√£o das regras de neg√≥cio.

### ‚è±Ô∏è 4. Tempo de Resposta do Banco
- **Solu√ß√µes recomendadas:**
  - Use **consultas planejadas** (projection) para limitar os dados retornados.
  - **Evite o problema de N+1 queries** (select N+1).
  - Configure o relacionamento **um para muitos** como **eager loading** (se a entidade filha for necess√°ria e n√£o impactar outros casos de uso).
  - Implemente **pagina√ß√£o** nas consultas para diminuir a quantidade de dados recuperados.

  **Benef√≠cio:** Menos dados retornados resultam em um tempo de resposta mais r√°pido.

### üí§ 5. Tempo que a Transa√ß√£o Fica Ociosa
- **Dica:** O **transaction response time** (considerando as otimiza√ß√µes acima) deve ser o menor poss√≠vel para aumentar o throughput.
- **Nota importante:** Criar novas conex√µes com o banco de dados √© uma opera√ß√£o cara. Portanto, o pool de conex√µes deve ser otimizado para evitar cria√ß√£o excessiva de conex√µes.

---

# Resumo de Melhores Pr√°ticas para Otimiza√ß√£o

- üìä **Mensure e teste** as configura√ß√µes de pool de conex√µes.
- üõ†Ô∏è **Prefira opera√ß√µes em lote** para reduzir o n√∫mero de round trips.
- üîç **Otimize as queries** com ferramentas como **EXPLAIN ANALYZE** e **√≠ndices**.
- üîÑ **Utilize window functions** e mantenha o processamento pr√≥ximo aos dados.
- üìù **Use consultas planejadas**, **eager loading** e **pagina√ß√£o** para otimizar o tempo de resposta do banco.
- ‚ö° **Reduza o transaction response time** para aumentar o throughput e minimizar a ociosidade das transa√ß√µes.


# Cache no Hibernate e Spring Boot

## üìå First Level Cache (Cache de Primeiro N√≠vel)
- Gerenciado pelo **EntityManager**.
- Armazena entidades dentro do **contexto da transa√ß√£o**.
- Se a mesma busca for feita v√°rias vezes dentro da mesma transa√ß√£o, os dados s√£o buscados do cache ao inv√©s do banco.

## üìå Second Level Cache (Cache de Segundo N√≠vel)
- Gerenciado pelo **EntityManagerFactory**.
- Cache compartilhado entre diferentes transa√ß√µes.
- **Habilita√ß√£o no Spring Boot**:
  1. Configurar o Hibernate no `application.properties`.
  2. Anotar as entidades com `@Cacheable` para habilitar o cache.
  3. Cachear relacionamentos se necess√°rio.

**‚ö†Ô∏è Apenas isso n√£o basta! Precisamos de um Fine Tuning.**

---

## üéØ Estrat√©gias de Cache no Hibernate
O Hibernate permite escolher a estrat√©gia de cache conforme a necessidade:

| Estrat√©gia | Uso recomendado |
|------------|----------------|
| `read-only` | Melhor para objetos imut√°veis (mais r√°pido e eficiente). |
| `non-strict-read-write` | Para dados n√£o cr√≠ticos, onde a consist√™ncia pode ser menor. |
| `read-write` | Mant√©m consist√™ncia com locks, mas √© mais lento. |

---

## üîß Configura√ß√£o do Cache
Al√©m de ativar e anotar as entidades, √© necess√°rio **configurar corretamente o provedor de cache**:

1. **Definir o provedor de cache**  
   - Exemplo: `EhcacheCachingProvider`.
   
2. **Configurar regi√µes de mem√≥ria**  
   - Usando `JCacheRegionFactory`.

3. **Especificar o arquivo de configura√ß√£o do EhCache**  
   - Definir pol√≠ticas de cache no arquivo XML (`ehcache.xml`).

4. **Configura√ß√£o por entidade**  
   - No arquivo `ehcache.xml`, configurar regras individuais para cada entidade cacheada.

---

## üöÄ Benef√≠cios do Cache
Atacamos diretamente o **Response Time**, melhorando:
- **Tempo de Requisi√ß√£o**
- **Tempo de Execu√ß√£o**
- **Tempo de Resposta**

Isso resulta em uma grande melhoria na **lat√™ncia** e no **throughput**.

---

## üõ†Ô∏è Cache no Spring Boot REST API
Tamb√©m podemos usar cache em APIs REST, por exemplo, em **controllers**, com a anota√ß√£o:

```java
@Cacheable("usuarios")
public Usuario getUsuario(Long id) {
    return usuarioRepository.findById(id).orElseThrow();
}
```

# üöÄ Processamento Ass√≠ncrono e Gerenciamento de Carga

## ‚è≥ N√£o processe hoje o que voc√™ pode processar amanh√£
- Processamentos que envolvem escrita e opera√ß√µes pesadas s√£o **custosos**.
- Se um processamento √© custoso, ele pode se tornar um **gargalo** no sistema.
- A solu√ß√£o para isso √© o **processamento ass√≠ncrono**.

---

## ‚öôÔ∏è Uso do `@Async` no Spring
- O Spring oferece a anota√ß√£o `@Async`, permitindo a execu√ß√£o ass√≠ncrona de m√©todos.
- Para cada requisi√ß√£o anotada com `@Async`, o Spring cria uma nova **thread** para process√°-la.
- Devemos decidir se otimizamos o **pool de threads** para **lat√™ncia** ou **throughput**, conforme a necessidade.

 ```java
@Async
public void processarPedido(Long pedidoId) {
    // Processamento ass√≠ncrono aqui
}
```

---

## üßµ Thread Pool Executor
- O `ThreadPoolExecutor` gerencia chamadas ass√≠ncronas enfileirando processos e alocando-os em **threads espec√≠ficas**.
- Durante **picos de carga**, um pool de threads pode n√£o ser suficiente, causando:
  - **Excesso de processos pendentes**
  - **Falta de mem√≥ria (`OutOfMemoryError`)**
  - **Reinicializa√ß√£o da aplica√ß√£o**
  - **Perda de itens na fila do pool de threads**

---

## üõ†Ô∏è Solu√ß√£o: Uso de Filas e Brokers
- Para lidar com **picos de carga**, precisamos de **filas mais robustas e dur√°veis**.
- Aqui entram os **brokers**, que atuam como **gerenciadores de fila**.

### üìå Substituindo `@Async` por consumidores de fila:
- Em vez de `@Async`, podemos utilizar **consumidores de fila**, como `@JmsListener` ou `@KafkaListener`.
- As **filas absorvem os picos de carga**.
- Os **consumers processam mensagens na taxa que conseguem suportar**.
- Esse mecanismo permite que o pr√≥prio **consumer

# Trade-offs em Sistemas Distribu√≠dos

## Performance vs Consist√™ncia

- Quanto mais distante da fonte verdadeira da informa√ß√£o, maior a performance, por√©m menor a consist√™ncia.
- √â comum termos redund√¢ncias de cache entre servi√ßos, mas isso pode gerar inconsist√™ncias, j√° que os caches podem ficar desatualizados.
- Uma alternativa √© tentar sincronizar os servi√ßos que dependem da mesma informa√ß√£o ‚Äî embora isso traga sua pr√≥pria complexidade.
- Um dos grandes desafios nesse cen√°rio √© o **cache invalidation**.
  - As estrat√©gias de invalida√ß√£o de cache variam de acordo com o contexto e a criticidade da consist√™ncia da informa√ß√£o.

## Lat√™ncia vs Throughput

- Em sistemas mais distribu√≠dos, geralmente se alcan√ßa maior **throughput**, mas com o custo de maior **lat√™ncia**.
- Ou seja:
  - **Mais distribui√ß√£o ‚Üí maior throughput**
  - **Mais n√≥s envolvidos ‚Üí maior lat√™ncia**

## Estrat√©gias de Cache

- Utilizar cache em mem√≥ria pode n√£o ser a melhor abordagem em todos os casos:
  - Pode causar problemas como **garbage collection** excessiva, **out of memory**, entre outros.
- Alternativa: utilizar uma solu√ß√£o de cache externa, como **Redis**.
  - Isso permite manter o estado fora da mem√≥ria da aplica√ß√£o.
  - Por√©m, a comunica√ß√£o com o cache se d√° via rede, o que pode adicionar lat√™ncia.

## Decis√µes de Arquitetura

- Em determinado momento, pode ser necess√°rio escolher entre **lat√™ncia** ou **throughput**.
- Em muitos cen√°rios, otimizar os dois ao mesmo tempo n√£o ser√° poss√≠vel ‚Äî sendo necess√°rio fazer **trade-offs** conscientes com base nos requisitos do neg√≥cio e nas limita√ß√µes t√©cnicas.


# Mudan√ßa de Workflow: De S√≠ncrono para Ass√≠ncrono

## Impactos e Desafios

### 1. Complexidade no Rastreamento de Falhas

- Em sistemas s√≠ncronos, falhas s√£o mais f√°ceis de identificar e tratar, pois ocorrem no mesmo fluxo de execu√ß√£o.
- J√° no modelo ass√≠ncrono, as falhas podem acontecer de forma desacoplada, tornando o **rastreio e monitoramento de erros mais complexo**.
- √â necess√°rio implementar estrat√©gias adicionais, como:
  - Logs distribu√≠dos
  - Correlation IDs
  - Sistemas de observabilidade (ex: tracing)

### 2. Redu√ß√£o da Testabilidade

- Testar workflows ass√≠ncronos √© mais dif√≠cil:
  - Envolve m√∫ltiplos componentes e filas/t√≥picos intermedi√°rios.
  - Pode ser necess√°rio mockar mensagerias ou usar ferramentas de testes integrados mais robustas.
- Isso exige **infraestrutura de testes mais elaborada** e maior cobertura de testes de integra√ß√£o e contrato.

### 3. Aumento da Complexidade no Desenvolvimento

- O modelo ass√≠ncrono exige mudan√ßas significativas na arquitetura:
  - Divis√£o em etapas (steps)
  - Gerenciamento de estados intermedi√°rios
  - Tratamento de reprocessamento e duplica√ß√µes
- Consequentemente, o **desenvolvimento se torna mais complexo**, exigindo mais aten√ß√£o a falhas parciais e consist√™ncia eventual.

## Ignorando o Feedback do Fluxo

- Em fluxos s√≠ncronos, √© comum aguardar uma resposta da chamada (acknowledgement).
- Ao mudar para um modelo **fire-and-forget** (ignorar o feedback da entrega):
  - Aumenta-se significativamente o **throughput**.
  - Por√©m, em caso de falha no envio ou na chamada, ela **ser√° ignorada**, podendo resultar em **perda de mensagens**.
- Essa abordagem s√≥ deve ser adotada quando:
  - A perda de mensagens for aceit√°vel.
  - Existirem mecanismos de compensa√ß√£o, retries ou auditoria paralela.

## Considera√ß√µes Finais

- A mudan√ßa para um modelo ass√≠ncrono pode trazer ganhos de escalabilidade e throughput, mas:
  - Aumenta a complexidade de desenvolvimento e opera√ß√£o.
  - Requer novos padr√µes de design e arquitetura.
  - Pode comprometer a confiabilidade e a rastreabilidade se n√£o for bem planejada.


# Lat√™ncia vs Consist√™ncia

- Em sistemas distribu√≠dos, especialmente em bancos de dados com r√©plicas, √© comum ocorrer **inconsist√™ncia de leitura**.
- Isso acontece, por exemplo, quando temos um banco de dados com **prim√°rio e r√©plicas**, sendo que as r√©plicas s√£o atualizadas de forma **ass√≠ncrona**.
- Esse √© um trade-off cl√°ssico: ao **priorizar lat√™ncia**, pode-se comprometer a **consist√™ncia imediata dos dados**.

---

# Coordination vs Race Conditions

- Quando m√∫ltiplas inst√¢ncias ou threads acessam e modificam dados ao mesmo tempo, √© necess√°rio algum mecanismo de **coordena√ß√£o** para garantir integridade.
- A aus√™ncia dessa coordena√ß√£o pode resultar em **race conditions**, onde o comportamento da aplica√ß√£o se torna imprevis√≠vel devido √† concorr√™ncia.

---

# Exemplo: Uso de `@Scheduled` do Spring com Acesso a Banco de Dados

- Suponha um cen√°rio onde uma tarefa agendada consulta e processa registros em uma tabela do banco.
- Se utilizarmos mecanismos locais, como `synchronized`, conseguimos garantir que apenas **uma thread da mesma JVM** execute determinada l√≥gica por vez.
- No entanto, esse tipo de controle √© **ineficaz em ambientes distribu√≠dos**, onde m√∫ltiplas inst√¢ncias da aplica√ß√£o est√£o em execu√ß√£o.

---

# Alternativa: Lock no Banco com Spring Data JPA

- Em ambientes com m√∫ltiplas inst√¢ncias, √© mais adequado utilizar **lock no banco de dados** para evitar que duas inst√¢ncias processem o mesmo registro ao mesmo tempo.
- A ideia √© que a inst√¢ncia que conseguir acessar um registro primeiro o bloqueie, garantindo exclusividade.
- As demais inst√¢ncias, ao tentarem acessar registros j√° bloqueados, devem simplesmente **pular para o pr√≥ximo registro dispon√≠vel**, evitando conflito.
- Essa abordagem melhora a coordena√ß√£o entre inst√¢ncias e reduz o risco de concorr√™ncia nos dados.

- Poderia ser usado por exemplo:

```java
@Lock(LockModeType.PESSIMISTIC_WRITE)
@Query("SELECT r FROM Registro r WHERE r.status = 'PENDENTE'")
List<Registro> buscarRegistrosParaProcessar();
```
